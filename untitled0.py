# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dQ89pkI0xUBFwlDfJ42DzA-TF2dCRuwN

# Noise Reduction
"""

from google.colab import drive
drive.mount('/content/drive')

import librosa
import numpy as np
import soundfile as sf
import os
import shutil

test= "/content/drive/MyDrive/data/clean_test_wav"
training= "/content/drive/MyDrive/data/clean_training_wav"

def add_noise_to_audio(audio_file_path, noise_level=0.005):
    # Load the audio file
    y, sr = librosa.load(audio_file_path, sr=None)

    # Generate noise
    noise = np.random.normal(0, noise_level, y.shape)

    # Add noise to the audio
    y_noisy = y + noise

    # Ensure values are within valid range
    y_noisy = np.clip(y_noisy, -1.0, 1.0)

    # Create the output file path
    noisy_audio_file_path = os.path.join('/content/drive/MyDrive/data/noisy_training', os.path.basename(audio_file_path))

    # Save the noisy audio
    sf.write(noisy_audio_file_path, y_noisy, sr)

    return noisy_audio_file_path

def process_multiple_files(input_directory, noise_level=0.005):
    noisy_files = []
    for root, _, files in os.walk(input_directory):
        for file in files:
            if file.endswith('.wav'):  #the audio files must be in .wav format
                file_path = os.path.join(root, file)
                noisy_file_path = add_noise_to_audio(file_path, noise_level)
                noisy_files.append(noisy_file_path)
    return noisy_files

# Example usage
input_directory = training
noise_level = 0.01  # Adjust the noise level as needed

noisy_files = process_multiple_files(input_directory, noise_level)

from google.colab import drive
drive.mount('/content/drive')

import librosa
import numpy as np
import soundfile as sf
import os
import shutil

test= "/content/drive/MyDrive/data/clean_test_wav"


def add_noise_to_audio(audio_file_path, noise_level=0.005):
    # Load the audio file
    y, sr = librosa.load(audio_file_path, sr=None)

    # Generate noise
    noise = np.random.normal(0, noise_level, y.shape)

    # Add noise to the audio
    y_noisy = y + noise

    # Ensure values are within valid range
    y_noisy = np.clip(y_noisy, -1.0, 1.0)

    # Create the output file path
    noisy_audio_file_path = os.path.join('/content/drive/MyDrive/data/noisy_test', os.path.basename(audio_file_path))

    # Save the noisy audio
    sf.write(noisy_audio_file_path, y_noisy, sr)

    return noisy_audio_file_path

def process_multiple_files(input_directory, noise_level=0.005):
    noisy_files = []
    for root, _, files in os.walk(input_directory):
        for file in files:
            if file.endswith('.wav'):  #the audio files must be in .wav format
                file_path = os.path.join(root, file)
                noisy_file_path = add_noise_to_audio(file_path, noise_level)
                noisy_files.append(noisy_file_path)
    return noisy_files


input_directory = test
noise_level = 0.01  # Adjust the noise level as needed

noisy_files = process_multiple_files(input_directory, noise_level)

import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import os

# Define the paths to your audio directories
clean_audio_dir = '/content/drive/MyDrive/data/clean_training__wav'
noisy_audio_dir = '/content/drive/MyDrive/data/noisy_training'

# Function to load an audio file
def load_audio(file_path, sr=22050):
    return librosa.load(file_path, sr=sr)

# Function to compute Mel spectrogram
def compute_mel_spectrogram(audio, sr, n_fft=2048, hop_length=512, n_mels=128):
    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)
    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)
    return mel_spectrogram_db

# Function to normalize spectrogram
def normalize_spectrogram(spectrogram):
    mean = np.mean(spectrogram)
    std = np.std(spectrogram)
    normalized_spectrogram = (spectrogram - mean) / std
    return normalized_spectrogram

# List all audio files in the directories
clean_audio_files = [os.path.join(clean_audio_dir, f) for f in os.listdir(clean_audio_dir) if f.endswith('.wav')]
noisy_audio_files = [os.path.join(noisy_audio_dir, f) for f in os.listdir(noisy_audio_dir) if f.endswith('.wav')]

# Process and visualize each audio file
for clean_audio_file, noisy_audio_file in zip(clean_audio_files, noisy_audio_files):
    clean_audio, sr = load_audio(clean_audio_file)
    noisy_audio, sr = load_audio(noisy_audio_file)

    clean_mel_spectrogram = compute_mel_spectrogram(clean_audio, sr)
    noisy_mel_spectrogram = compute_mel_spectrogram(noisy_audio, sr)

    normalized_clean_spectrogram = normalize_spectrogram(clean_mel_spectrogram)
    normalized_noisy_spectrogram = normalize_spectrogram(noisy_mel_spectrogram)

    # Visualize the clean spectrogram
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(normalized_clean_spectrogram, sr=sr, hop_length=512, x_axis='time', y_axis='mel')
    plt.colorbar(format='%+2.0f dB')
    plt.title(f'Normalized Mel Spectrogram (Clean) - {os.path.basename(clean_audio_file)}')
    plt.tight_layout()
    plt.show()

    # Visualize the noisy spectrogram
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(normalized_noisy_spectrogram, sr=sr, hop_length=512, x_axis='time', y_axis='mel')
    plt.colorbar(format='%+2.0f dB')
    plt.title(f'Normalized Mel Spectrogram (Noisy) - {os.path.basename(noisy_audio_file)}')
    plt.tight_layout()
    plt.show()

"""# Model architecture (U Net)"""

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate
import numpy as np
import librosa
from librosa import load, feature  # Import librosa for audio processing


def unet_model(input_shape):
  inputs = Input(input_shape)

  # Encoder
  conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

  # Decoder
  conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)
  up1 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv2)

  # Output
  outputs = Conv2D(1, 1, activation='linear', padding='same')(up1)

  model = Model(inputs=inputs, outputs=outputs)
  return model


# Define input shape
input_shape = ( 128, 128, 1)

# Create the U-Net model
model = unet_model(input_shape)


# Compile the model (consider using a more suitable loss function like mean squared error with logarithmic magnitude (see note))
model.compile(optimizer='adam', loss='mse')  # Mean squared error

# Load and pre-process audio data
clean_audio_files = sorted(tf.io.gfile.glob('/content/drive/MyDrive/data/clean_training__wav/*.wav'))
noisy_audio_files = sorted(tf.io.gfile.glob('/content/drive/MyDrive/data/noisy_training/*.wav'))

clean_data = []
noisy_data = []
for clean_file, noisy_file in zip(clean_audio_files, noisy_audio_files):
  clean_wav, _ = load(clean_file)
  noisy_wav, _ = load(noisy_file)

  # Pre-process audio (convert to spectrograms) - Example
  clean_spec = feature.melspectrogram(y=clean_wav)
  # Convert to decibel scale (optional, might be better for training)
  clean_spec_db = librosa.power_to_db(clean_spec)
  noisy_spec = feature.melspectrogram(y=noisy_wav)
  noisy_spec_db = librosa.power_to_db(noisy_spec)

  # Resize spectrograms to a consistent shape (e.g., 128x128)
  clean_spec_db = tf.image.resize(clean_spec_db[:, :, np.newaxis], [128, 128])
  noisy_spec_db = tf.image.resize(noisy_spec_db[:, :, np.newaxis], [128, 128])

  clean_data.append(clean_spec_db)  # Append pre-processed data
  noisy_data.append(noisy_spec_db)

# Convert to NumPy arrays
X_train = np.array(clean_data)
y_train = np.array(noisy_data)

# Train the model
model.fit(X_train, y_train, epochs=30)

model.save('/content/drive/MyDrive/data/my_unet_model.h5')

import os
from tensorflow.keras.models import load_model
import librosa
import numpy as np
# Load the model
model = load_model('/content/drive/MyDrive/data/my_unet_model.h5')

def evaluate_model(model, test_clean_files, test_noisy_files):
    X_test = []
    y_test = []
    for clean_file, noisy_file in zip(test_clean_files, test_noisy_files):
        # Load audio files
        clean_wav, _ = librosa.load(clean_file)
        noisy_wav, _ = librosa.load(noisy_file)

        # Pre-process audio (convert to spectrograms)
        clean_spec = librosa.feature.melspectrogram(y=clean_wav)
        clean_spec_db = librosa.power_to_db(clean_spec)
        noisy_spec = librosa.feature.melspectrogram(y=noisy_wav)
        noisy_spec_db = librosa.power_to_db(noisy_spec)

        # Resize spectrograms to a consistent shape (e.g., 128x128)
        clean_spec_db = tf.image.resize(clean_spec_db[:, :, np.newaxis], [128, 128])
        noisy_spec_db = tf.image.resize(noisy_spec_db[:, :, np.newaxis], [128, 128])

        X_test.append(clean_spec_db)
        y_test.append(noisy_spec_db)

    # Convert to NumPy arrays
    X_test = np.array(X_test)
    y_test = np.array(y_test)

    loss = model.evaluate(X_test, y_test)
    print(f"Test Loss: {loss}")
    return loss

# Paths to test data directories
test_clean_audio_dir = '/content/drive/MyDrive/data/test/clean_test_wav'
test_noisy_audio_dir = '/content/drive/MyDrive/data/noisy_test'

# Load and preprocess test data
test_clean_files = sorted([os.path.join(test_clean_audio_dir, f) for f in os.listdir(test_clean_audio_dir) if f.endswith('.wav')])
test_noisy_files = sorted([os.path.join(test_noisy_audio_dir, f) for f in os.listdir(test_noisy_audio_dir) if f.endswith('.wav')])

# Evaluate the model
evaluate_model(model, test_clean_files, test_noisy_files)

# Denoise audio using the trained model
def denoise_audio(model, noisy_file, output_dir, target_size=(128, 128)):
    try:
        noisy_wav, sr = librosa.load(noisy_file)
        noisy_spec = librosa.feature.melspectrogram(y=noisy_wav)
        noisy_spec_db = librosa.power_to_db(noisy_spec)
        noisy_spec_db = tf.image.resize(noisy_spec_db[:, :, np.newaxis], target_size)

        noisy_spec_db = np.expand_dims(noisy_spec_db, axis=0)
        denoised_spec_db = model.predict(noisy_spec_db)[0]

        denoised_audio = librosa.feature.inverse.mel_to_audio(librosa.db_to_power(denoised_spec_db[:, :, 0]), sr=sr)
        output_file = os.path.join(output_dir, os.path.basename(noisy_file))
        sf.write(output_file, denoised_audio, sr)
        print(f"Denoised audio saved to {output_file}")

    except Exception as e:
        print(f"Error processing {noisy_file}: {e}")

# Main script
if __name__ == "__main__":
    clean_audio_dir = '/content/drive/MyDrive/data/clean_training__wav'
    noisy_audio_dir = '/content/drive/MyDrive/data/noisy_training'
    model_save_path = '/content/drive/MyDrive/data/my_unet_model.h5'



    # Load the trained model
    model = load_model(model_save_path)

    # Paths to test data directories
    test_clean_audio_dir = '/content/drive/MyDrive/data/test/clean_test_wav'
    test_noisy_audio_dir = '/content/drive/MyDrive/data/noisy_test'

    # Load and preprocess test data
    test_clean_files = sorted([os.path.join(test_clean_audio_dir, f) for f in os.listdir(test_clean_audio_dir) if f.endswith('.wav')])
    test_noisy_files = sorted([os.path.join(test_noisy_audio_dir, f) for f in os.listdir(test_noisy_audio_dir) if f.endswith('.wav')])


    # Denoise the test audio files
    denoised_audio_dir = '/content/drive/MyDrive/data/denoised_audio'
    os.makedirs(denoised_audio_dir, exist_ok=True)
    for noisy_file in test_noisy_files:
        denoise_audio(model, noisy_file, denoised_audio_dir)

!git clone https://github.com/Tripti1298/IITI-SOC-speech-enhancer.git